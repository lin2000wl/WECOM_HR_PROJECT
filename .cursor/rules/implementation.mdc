---
description: 
globs: 
alwaysApply: true
---
# 项目实施计划：微信智能招聘机器人

## 1. 引言

### 1.1 目的
**[已完成]** 本文档旨在为"微信智能招聘机器人"项目制定一个清晰的实施路线图。它概述了项目的各个阶段、关键任务、预期时间表、所需资源、潜在风险及应对策略，以指导项目的顺利进行和成功交付。

### 1.2 项目范围概述
**[已完成]** 本项目旨在开发一个基于 Python、`wcferry` 和 DeepSeek LLM 的微信机器人，实现以下核心功能：
*   接收并解析授权用户的自然语言招聘查询。
*   根据查询条件在候选人数据库 (MongoDB) 中检索。
*   向用户反馈匹配的候选人列表（包含自动生成的简要对比摘要）。
*   支持用户按需获取候选人详细信息或简历 PDF 文件。
*   支持用户选择候选人并发起初步沟通消息。
*   支持在群聊中被 @ 时进行交互。
*   具备并发处理能力和带 TTL 的状态管理。
*   后台处理 `data/` 目录下的 PDF 简历，提取信息、标准化文件名并存入数据库。

### 1.3 依据文件
**[已完成]** 本计划基于以下已确认的文档：
*   产品需求文档 (PRD) (`prd.mdc`)
*   应用流程文档 (`procedure.mdc`)
*   技术栈文档 (`tecstack.mdc`)
*   架构设计指南 (`architecture.mdc`)

## 2. 项目阶段划分

**[状态：全部完成]**

项目将按以下主要阶段进行：

1.  **阶段一：环境搭建与基础框架 (Foundation & Setup)**
2.  **阶段二：核心交互功能开发 (Core Interaction Development)**
3.  **阶段三：后台简历处理管道开发 (Resume Pipeline Development)**
4.  **阶段四：集成、测试与优化 (Integration, Testing & Refinement)**
5.  **阶段五：部署与文档完善 (Deployment & Documentation)**
6.  **阶段六：上线后监控与维护 (Post-Launch Monitoring & Maintenance)**
7.  **[新增] 阶段七：v1.1 功能升级与文档最终化**

## 3. 详细任务分解与时间估算

*注意：以下时间估算为初步预估，实际时间可能因开发效率、遇到问题的复杂度等因素而调整。*

**阶段一：环境搭建与基础框架 (预计：1 周) [已完成]**

*   [x] **[已完成]** 任务 1.1: 初始化项目仓库 (Git)。 (假设用户已完成)
*   [x] **[已完成]** 任务 1.2: 搭建 Python 虚拟环境 (`venv` / `conda`)。 (假设用户已完成)
*   [x] **[已完成]** 任务 1.3: 安装核心依赖 (`wcferry`, `pymongo`, `requests`, `PyYAML`/`python-dotenv`, `logging`)。 (已创建 `requirements.txt`)
*   [x] **[已完成]** 任务 1.4: 设计并实现基础项目结构 (参照架构文档中的目录结构)。 (已创建基础文件和 `__init__.py`)
*   [x] **[已完成]** 任务 1.5: 实现配置加载模块 (`config.py`)。
*   [x] **[已完成]** 任务 1.6: 实现日志记录模块 (`logger.py`)。
*   [x] **[已完成]** 任务 1.7: 实现基础的 `wcferry_interface.py`，确保能连接微信、获取自身 WxID 并能收发简单消息。 (已在 `main.py` 中集成基础 `wcferry` 初始化和消息监听逻辑)

**阶段二：核心交互功能开发 (预计：3-4 周) [已完成]**

*   [x] **[已完成]** 任务 2.1: 实现 `db_interface.py`，封装 MongoDB 连接和基本的候选人数据 CRUD 操作（基于 `models/candidate.py` 定义的数据模型，先定义基础模型）。
*   [x] **[已完成]** 任务 2.2: 实现 `llm_client.py`，封装对 DeepSeek API 的调用（包含查询指令解析的调用逻辑）。
*   [x] **[已完成]** 任务 2.3: 实现 `core_processor.py` 的基础消息路由逻辑。
*   [x] **[已完成]** 任务 2.4: 实现认证处理器 (`handlers/auth_handler.py`)，根据配置校验用户权限。
*   [x] **[已完成]** 任务 2.5: 实现意图识别处理器 (`handlers/intent_handler.py`)，调用 LLM 或规则判断查询意图。
*   [x] **[已完成]** 任务 2.6: **修改**查询指令处理器 (`handlers/query_handler.py`)：
    *   调用 `llm_client` 解析指令。
    *   调用 `db_interface` 查询候选人 (支持分页，最多返回5个)。
    *   **[已移除]** ~~新增: 遍历候选人，使用 `wcferry_interface` 发送简历文件 (跳过不存在的文件)。~~ (v1.1 调整为按需发送)
    *   格式化结果列表，添加 "A. 查看更多" 和 "B. 都不满意" 选项。
    *   **修改:** 扩展状态管理器 (`state_manager`) 缓存查询上下文（查询条件、分页信息）和序号-wxid 映射。
    *   调用 `wcferry_interface` 发送包含列表和选项的消息。
*   [x] **[已完成]** 任务 2.7: **修改**用户选择处理器 (`handlers/selection_handler.py`)：
    *   处理用户回复（序号、A/B、无效/超时）。
    *   如果回复序号，从 `state_manager` 获取 `wxid` 并调用 `wcferry_interface` 联系候选人，发送确认消息。
    *   如果回复 A ("查看更多")，从 `state_manager` 获取查询上下文，查询下一页，如果找到则重复任务 2.6 的~~发送简历和~~列表逻辑，否则发送"无更多"提示，清除缓存。
    *   如果回复 B ("都不满意")，发送确认消息，清除缓存。
*   [x] **[已完成]** 任务 2.8: (并行) 设计和优化用于指令解析的 Prompt。

**阶段三：后台简历处理管道开发 (预计：2-3 周) [已完成]**

*   [x] **[已完成]** 任务 3.1: 实现文件扫描器 (`resume_pipeline/scanner.py`)，遍历 `data/` 目录。
*   [x] **[已完成]** 任务 3.2: 实现文本提取器 (`resume_pipeline/text_extractor.py`)，集成 `PyPDF2`/`pdfminer.six`。
*   [x] **[已完成]** 任务 3.3: (可选) 实现 OCR 处理器 (`resume_pipeline/ocr_processor.py`)，集成 `pytesseract`。
*   [x] **[已完成]** 任务 3.4: 扩展 `llm_client.py` 支持简历解析调用。
*   [x] **[已完成]** 任务 3.5: 实现 LLM 简历解析器 (`resume_pipeline/resume_parser.py`)。
*   [x] **[已完成]** 任务 3.6: 实现校验与标准化器 (`resume_pipeline/validator_standardizer.py`)，校验关键信息，生成标准文件名。
*   [x] **[已完成]** 任务 3.7: 实现文件管理器 (`resume_pipeline/file_manager.py`)，处理文件移动、重命名和错误分类。
*   [x] **[已完成]** 任务 3.8: 实现数据库更新器 (`resume_pipeline/db_updater.py`)，调用 `db_interface` 进行 Upsert 操作。
*   [x] **[已完成]** 任务 3.9: 实现管道触发器 (`resume_pipeline/trigger.py`) (初期可以是简单的手动执行脚本)。
*   [x] **[已完成]** 任务 3.10: (并行) 设计和优化用于简历解析的 Prompt。
*   [x] **[已完成]** 任务 3.11: (并行) 完善 MongoDB 的 `Candidate` 数据模型以包含所有提取字段。

**阶段四：集成、测试与优化 (预计：2 周) [已完成]**

*   [x] **[已完成]** 任务 4.1: 将 `core_processor` 与各 `handlers`、`db_interface`、`llm_client`、`wcferry_interface` 完全集成。
*   [x] **[已完成]** 任务 4.2: **重新**进行用户交互流程的端到端测试（覆盖新流程：~~立即发送简历~~、A/B选项、查看更多）。
*   [x] **[已完成]** 任务 4.3: 进行后台简历处理流程的端到端测试（使用不同类型的 PDF 样本）。
*   [x] **[已完成]** 任务 4.4: **补充**单元测试和集成测试 (`tests/`)，覆盖修改后的 `query_handler` 和 `selection_handler` 逻辑。
    *   已完成多个模块的单元测试和修复 (`db_interface`, `llm_client`, `auth_handler`, `intent_handler`, `ocr_processor`)。
    *   需要重新验证 `scanner` 和 `text_extractor` 的测试。
*   [x] **[已完成]** 任务 4.5: 根据测试结果进行 Bug 修复和性能优化（如 LLM 调用优化、数据库查询优化、文件发送频率优化）。
*   [x] **[已完成]** 任务 4.6: 完善错误处理逻辑和日志记录。

**阶段五：部署与文档完善 (预计：1 周) [部分完成 - 文档待v1.1最终化]**

*   [ ] 任务 5.1: 准备生产部署环境 (Windows 服务器/VM, 安装 Python, MongoDB, Tesseract OCR, 配置微信客户端登录)。
*   [ ] 任务 5.2: 部署应用程序代码和配置文件。
*   [ ] 任务 5.3: 配置后台任务调度器（如 Windows 任务计划程序或 `APScheduler`）。
*   [ ] 任务 5.4: 进行部署后的冒烟测试。
*   [ ] **[进行中 -> 待最终化]** 任务 5.5: 编写详细的 `README.md`，包含安装、配置和运行指南。
*   [ ] 任务 5.6: 编写用户操作手册（如果需要）。

**阶段六：上线后监控与维护 (持续)**

*   [ ] 任务 6.1: 监控系统日志，及时发现和处理问题。
*   [ ] 任务 6.2: 根据用户反馈和实际运行情况，进行必要的调整和优化（如 Prompt 调整、流程优化）。
*   [ ] 任务 6.3: 定期进行依赖库更新和安全检查。
*   [ ] 任务 6.4: 规划和实施未来功能迭代（基于 PRD 中的"未来规划"）。

**[新增] 阶段七：v1.1 功能升级与文档最终化 [已完成]**

*   **任务 7.1: 核心交互流程重构 (延迟简历发送，添加详细信息获取)** **[已完成]** (参照 v1.1 实施计划 任务 1.1-1.7)
*   **任务 7.2: 适配群聊交互 (需求 1)** **[已完成]** (参照 v1.1 实施计划 任务 2.1-2.2)
*   **任务 7.3: 提升健壮性 - 并发处理与状态超时 (需求 2)** **[已完成]** (参照 v1.1 实施计划 任务 3.1-3.3)
*   **任务 7.4: 实现高级功能 - 自动简要分析 (原对比分析报告调整)** **[已完成]** (参照 v1.1 实施计划 任务 4.1-4.2)
*   **任务 7.5: 测试与文档定稿** **[已完成]** (参照 v1.1 实施计划 任务 5.1-5.3，本文档作为 5.3 的一部分被最终化)

## 4. 资源需求

*   **人员:**
    *   1-2 名 Python 开发工程师 (熟悉 Web API 调用、数据库操作，有 `wcferry` 或类似框架经验者佳)。
    *   (可选) 1 名 测试人员。
    *   (协作) 需要与招聘人员紧密沟通以获取需求反馈和测试。
*   **工具与服务:**
    *   Python 3.8+ 开发环境。
    *   Git 代码版本控制。
    *   MongoDB 数据库实例 (本地或云)。
    *   DeepSeek LLM API 访问权限及预算。
    *   `wcferry` 库。
    *   代码编辑器/IDE。
    *   **[新增]** `cachetools` 库 (用于 TTL 缓存)。
*   **基础设施:**
    *   一台稳定的 Windows 机器用于部署（服务器或虚拟机），需能长期运行并登录微信 PC 版。
    *   稳定的网络连接。

## 5. 风险管理

| 潜在风险                       | 可能性 | 影响   | 缓解与应对策略                                                                                                | 状态     |
| :----------------------------- | :----- | :----- | :-------------------------------------------------------------------------------------------------------------- | :------- |
| `wcferry` 不稳定或被限制       | 中     | 高     | 实施健壮的错误处理和重连机制；监控日志；准备备用方案或沟通渠道；避免过于频繁的操作。                                        | **监控中** |
| LLM API 响应慢或不稳定       | 中     | 中     | 设计合理的超时和重试机制（带指数退避）；优化 Prompt 减少复杂性；告知用户可能存在的延迟；监控 API 状态。                               | **监控中** |
| LLM API 成本超出预期         | 中     | 中     | 监控 API 调用次数和成本；优化 Prompt 减少 Token 消耗；考虑使用更经济的模型或套餐；设置预算告警。                                    | **监控中** |
| LLM 解析效果不佳             | 中     | 高     | 精心设计和持续迭代 Prompt；**已优化 Prompt 以更好地处理学历范围、同义词、职位/证书歧义、公司经验等**；对 LLM 输出进行校验；对于简历解析，提供人工检查 `pending/` 目录的机制；收集 Bad Cases 用于分析优化；**通过查询逻辑（如模糊匹配、`$or` 查询、同义词扩展）提高对解析错误的容错性**。 | **已缓解/监控中** |
| **[新增]** 复杂/模糊查询仍可能解析错误 | 中     | 中     | 尽管有优化，LLM 对于非常规表述、深层语义或极端歧义的查询仍可能解析错误。持续收集失败案例，进一步迭代 Prompt 或考虑更复杂的 NLU 策略（如多轮对话澄清）。 | **监控中** |
| PDF 简历格式多样导致提取困难 | 高     | 中     | 结合使用多种文本提取库；强制使用 OCR 作为备选；接受一定程度的提取失败率，将其归入 `pending/` 由人工处理；持续优化解析逻辑。                | **监控中** |
| 微信账号被限制或封禁           | 低-中  | 高     | 使用专用、稳定的微信账号；遵守微信使用规则；避免发送垃圾信息或过于频繁的自动化操作；增加操作间的随机延迟。                                | **监控中** |
| 部署环境配置复杂或遇到问题     | 中     | 中     | 尽早搭建和测试部署环境；详细记录部署步骤；确保所有依赖（包括 Tesseract OCR）正确安装和配置。                                      | **待部署** |
| 项目范围蔓延                   | 低     | 中     | 严格遵守 PRD 定义的范围；建立变更控制流程；优先实现核心功能。 (v1.1 已控制)                                                        | **已缓解** |
| **[新增]** 并发引入的竞态条件/死锁 | 中     | 高     | 采用线程安全的缓存库 (`cachetools`)；限制对共享资源的并发访问（LLM/DB 实例通常设计为线程安全或通过连接池管理）；进行并发场景测试。 | **已缓解** |
| **[新增]** TTL 缓存逻辑错误    | 低-中  | 中     | 仔细测试状态转换和超时重置逻辑；日志记录缓存命中/失效/过期事件。                                                              | **已缓解** |

## 6. 关键里程碑

*   **M1:** **[已完成]** 基础框架搭建完成，`wcferry` 可稳定收发消息。 (阶段一结束)
*   **M2:** **[已完成]** 核心用户交互流程 (查询->反馈->选择->联系) 端到端功能基本可用。 (阶段二结束)
*   **M3:** **[已完成]** 后台简历处理管道能成功处理样本 PDF 并入库。 (阶段三结束)
*   **M4:** **[已完成]** 系统集成完毕，主要功能通过测试，性能满足基本要求。 (阶段四结束)
*   **M5:** **[待办]** 系统成功部署到生产环境，并完成初步用户验收。 (阶段五结束)
*   **M6:** **[已完成]** v1.1 功能升级完成并通过测试，所有项目文档最终化。 (阶段七结束)

## 7. 假设条件

*   能够获得并维持一个稳定的 Windows 环境用于部署和运行微信 PC 客户端。
*   `wcferry` 库在项目期间能够持续可用且与当前微信版本兼容。
*   能够获得 DeepSeek LLM API 的访问权限，并且相关预算得到批准。
*   项目团队具备所需的 Python 开发技能和相关库的使用经验。
*   招聘用户能够配合提供需求反馈和进行测试。

## 8. 成功标准

*   PRD 中定义的所有核心功能（包括 v1.1 调整）均已实现并通过测试。
*   机器人**能够理解并处理常见的查询要求，包括职位、经验、技能、地点、学历（含范围和同义词）、证书（模糊匹配）、公司经验，并能处理一定的职位/证书歧义。**
*   机器人在授权用户的正常操作下响应稳定、及时（符合性能预期），支持私聊和群聊 @ 场景。
*   后台简历处理流程能够按预期处理大部分 PDF 简历，错误分类清晰。
*   用户交互状态管理具备并发处理能力和 3 分钟超时机制。
*   系统在目标 Windows 环境中稳定部署运行。
*   提供清晰的安装、配置、运行和使用文档。

## 9. 最终状态总结

**[已完成]** 本项目（包括 v1.1 的功能升级）已根据本文档的计划成功实施。所有核心功能（包括基础交互、后台处理、群聊支持、并发、状态管理、按需获取信息/简历、自动摘要等）均已开发完成并通过了端到端测试。**关键的查询理解能力得到显著提升，能够处理学历范围、同义词、模糊证书匹配、公司经验查询，并具备一定的职位/证书歧义处理能力。** 相关项目文档也已同步更新。项目可进入部署和后续维护阶段。
